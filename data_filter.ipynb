{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 27 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   year        54 non-null     int64         \n",
      " 1   month       54 non-null     int64         \n",
      " 2   day         54 non-null     int64         \n",
      " 3   hour        54 non-null     int64         \n",
      " 4   min         54 non-null     int64         \n",
      " 5   sec         54 non-null     int64         \n",
      " 6   recno       54 non-null     int64         \n",
      " 7   kindat      54 non-null     int64         \n",
      " 8   kinst       54 non-null     int64         \n",
      " 9   ut1_unix    54 non-null     float64       \n",
      " 10  ut2_unix    54 non-null     float64       \n",
      " 11  pierce_alt  54 non-null     float64       \n",
      " 12  gps_site    54 non-null     object        \n",
      " 13  sat_id      54 non-null     int64         \n",
      " 14  gnss_type   54 non-null     object        \n",
      " 15  gdlatr      54 non-null     float64       \n",
      " 16  gdlonr      54 non-null     float64       \n",
      " 17  los_tec     54 non-null     float64       \n",
      " 18  dlos_tec    54 non-null     float64       \n",
      " 19  tec         54 non-null     float64       \n",
      " 20  azm         54 non-null     float64       \n",
      " 21  elm         54 non-null     float64       \n",
      " 22  gdlat       54 non-null     float64       \n",
      " 23  glon        54 non-null     float64       \n",
      " 24  rec_bias    54 non-null     float64       \n",
      " 25  drec_bias   54 non-null     float64       \n",
      " 26  datetime    54 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(14), int64(10), object(2)\n",
      "memory usage: 11.5+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "   year  month  day  hour  min  sec  recno  kindat  kinst      ut1_unix  ...  \\\n",
      "0  2011      3   11     0    0    0      0    3505   8000  1.299802e+09  ...   \n",
      "1  2011      3   11     0    0    0      0    3505   8000  1.299802e+09  ...   \n",
      "2  2011      3   11     0    0    0      0    3505   8000  1.299802e+09  ...   \n",
      "3  2011      3   11     0    0    0      0    3505   8000  1.299802e+09  ...   \n",
      "4  2011      3   11     0    0    0      0    3505   8000  1.299802e+09  ...   \n",
      "\n",
      "     los_tec  dlos_tec        tec         azm        elm      gdlat  \\\n",
      "0  18.032875  0.467428  12.436886  -56.489273  40.339066  42.700172   \n",
      "1  15.488737  0.440063  15.061049   -9.582431  75.779404  41.630527   \n",
      "2  40.065205  0.188305  16.253223 -112.361443  15.819306  37.247559   \n",
      "3  17.571890  0.173197  15.743333  -98.635773  62.124218  40.633560   \n",
      "4  26.613272  0.570833  10.141697  -70.533440  13.293839  43.389851   \n",
      "\n",
      "         glon       rec_bias  drec_bias   datetime  \n",
      "0  137.018890 -215235.828125   1.301747 2011-03-11  \n",
      "1  140.692001 -215212.953125   1.301781 2011-03-11  \n",
      "2  131.067474 -215218.468750   1.301716 2011-03-11  \n",
      "3  138.819244 -215216.343750   1.301632 2011-03-11  \n",
      "4  128.688339 -215219.078125   1.302975 2011-03-11  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_filtered_data(file_path, lat_range=(39, 41), lon_range=(140, 142), max_entries=4500):\n",
    "    \"\"\"\n",
    "    Extract and filter HDF5 data for specified attributes within coordinate ranges.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to HDF5 file\n",
    "        lat_range (tuple): Range of latitude (min, max)\n",
    "        lon_range (tuple): Range of longitude (min, max)\n",
    "        max_entries (int): Maximum number of entries to process\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing filtered data with all attributes\n",
    "    \"\"\"\n",
    "    # Define all attributes to extract\n",
    "    attributes = [\n",
    "        'year', 'month', 'day', 'hour', 'min', 'sec', 'recno', 'kindat', 'kinst',\n",
    "        'ut1_unix', 'ut2_unix', 'pierce_alt', 'gps_site', 'sat_id', 'gnss_type',\n",
    "        'gdlatr', 'gdlonr', 'los_tec', 'dlos_tec', 'tec', 'azm', 'elm',\n",
    "        'gdlat', 'glon', 'rec_bias', 'drec_bias'\n",
    "    ]\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as hdf:\n",
    "        # Get the dataset\n",
    "        dataset = hdf['Data/Table Layout']\n",
    "        \n",
    "        # Read only the first max_entries\n",
    "        data = dataset[:max_entries]\n",
    "        \n",
    "        # Extract coordinates for filtering\n",
    "        lats = data['gdlatr']  # receiver latitude\n",
    "        lons = data['gdlonr']  # receiver longitude\n",
    "        \n",
    "        # Create mask for the coordinate ranges\n",
    "        mask = (lats >= lat_range[0]) & (lats <= lat_range[1]) & \\\n",
    "               (lons >= lon_range[0]) & (lons <= lon_range[1])\n",
    "        \n",
    "        # Create dictionary to store filtered data\n",
    "        filtered_data = {}\n",
    "        \n",
    "        # Extract each attribute and apply mask\n",
    "        for attr in attributes:\n",
    "            if attr in data.dtype.names:\n",
    "                filtered_values = data[attr][mask]\n",
    "                \n",
    "                # Convert bytes to strings for string columns\n",
    "                if filtered_values.dtype.kind == 'S':\n",
    "                    filtered_values = [val.decode('utf-8') for val in filtered_values]\n",
    "                \n",
    "                filtered_data[attr] = filtered_values\n",
    "        \n",
    "        # Create pandas DataFrame\n",
    "        df = pd.DataFrame(filtered_data)\n",
    "        \n",
    "        # Rename 'min' and 'sec' columns to 'minute' and 'second' for datetime conversion\n",
    "        df = df.rename(columns={'min': 'minute', 'sec': 'second'})\n",
    "        \n",
    "        try:\n",
    "            # Add datetime column for convenience\n",
    "            df['datetime'] = pd.to_datetime(\n",
    "                df[['year', 'month', 'day', 'hour', 'minute', 'second']]\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not create datetime column: {e}\")\n",
    "            # If datetime creation fails, we still want to return the DataFrame\n",
    "            pass\n",
    "        \n",
    "        # Rename back to original column names if you prefer\n",
    "        df = df.rename(columns={'minute': 'min', 'second': 'sec'})\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Example usage\n",
    "file_path = r'/mnt/c/Users/fadri_oudurqw/Downloads/los_20110311.001_Jap_Tsu.h5'\n",
    "df = extract_filtered_data(file_path, max_entries=100_000)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('data/data_csvs/Japan_Tsunami_11Mar2011.csv', index=False)\n",
    "\n",
    "# Example usage with full args*\n",
    "# df = extract_filtered_data(file_path, lat_range=(39, 41), lon_range=(140, 142), max_entries=100)\n",
    "\n",
    "# Display information about the resulting DataFrame\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /mnt/c/Users/fadri_oudurqw/Downloads/los_20160326.001.h5\n",
      "\n",
      "Structure:\n",
      "Group: Data\n",
      "    Dataset: Data/Table Layout\n",
      "        Shape: (111787628,)\n",
      "        Type: [('year', '<i8'), ('month', '<i8'), ('day', '<i8'), ('hour', '<i8'), ('min', '<i8'), ('sec', '<i8'), ('recno', '<i8'), ('kindat', '<i8'), ('kinst', '<i8'), ('ut1_unix', '<f8'), ('ut2_unix', '<f8'), ('pierce_alt', '<f8'), ('gps_site', 'S4'), ('sat_id', '<i8'), ('gdlatr', '<f8'), ('gdlonr', '<f8'), ('los_tec', '<f8'), ('dlos_tec', '<f8'), ('tec', '<f8'), ('azm', '<f8'), ('elm', '<f8'), ('gdlat', '<f8'), ('glon', '<f8'), ('rec_bias', '<f8'), ('drec_bias', '<f8')]\n",
      "Group: Metadata\n",
      "    Dataset: Metadata/Data Parameters\n",
      "        Shape: (25,)\n",
      "        Type: [('mnemonic', 'S10'), ('description', 'S50'), ('isError', '<i8'), ('units', 'S7'), ('category', 'S36')]\n",
      "    Dataset: Metadata/Experiment Parameters\n",
      "        Shape: (14,)\n",
      "        Type: [('name', 'S20'), ('value', 'S46')]\n",
      "    Dataset: Metadata/Independent Spatial Parameters\n",
      "        Shape: (2,)\n",
      "        Type: [('mnemonic', 'S8'), ('description', 'S29')]\n",
      "    Dataset: Metadata/_record_layout\n",
      "        Shape: (1,)\n",
      "        Type: [('year', '<i8'), ('month', '<i8'), ('day', '<i8'), ('hour', '<i8'), ('min', '<i8'), ('sec', '<i8'), ('recno', '<i8'), ('kindat', '<i8'), ('kinst', '<i8'), ('ut1_unix', '<i8'), ('ut2_unix', '<i8'), ('pierce_alt', '<i8'), ('gps_site', '<i8'), ('sat_id', '<i8'), ('gdlatr', '<i8'), ('gdlonr', '<i8'), ('los_tec', '<i8'), ('dlos_tec', '<i8'), ('tec', '<i8'), ('azm', '<i8'), ('elm', '<i8'), ('gdlat', '<i8'), ('glon', '<i8'), ('rec_bias', '<i8'), ('drec_bias', '<i8')]\n"
     ]
    }
   ],
   "source": [
    "# import h5py\n",
    "\n",
    "# def explore_h5(file_path):\n",
    "#     \"\"\"\n",
    "#     Explore the structure of an HDF5 file and print all groups and datasets with their paths.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     file_path : str\n",
    "#         Path to the HDF5 file\n",
    "#     \"\"\"\n",
    "#     def print_structure(name, obj):\n",
    "#         \"\"\"Callback function to print the structure\"\"\"\n",
    "#         indent = '    ' * name.count('/')\n",
    "#         if isinstance(obj, h5py.Dataset):\n",
    "#             print(f\"{indent}Dataset: {name}\")\n",
    "#             print(f\"{indent}    Shape: {obj.shape}\")\n",
    "#             print(f\"{indent}    Type: {obj.dtype}\")\n",
    "#         elif isinstance(obj, h5py.Group):\n",
    "#             print(f\"{indent}Group: {name}\")\n",
    "    \n",
    "#     try:\n",
    "#         with h5py.File(file_path, 'r') as f:\n",
    "#             print(f\"File: {file_path}\")\n",
    "#             print(\"\\nStructure:\")\n",
    "#             # Recursively visit all groups and datasets\n",
    "#             f.visititems(print_structure)\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error occurred: {str(e)}\")\n",
    "\n",
    "# # Example usage:\n",
    "# explore_h5('/mnt/c/Users/fadri_oudurqw/Downloads/los_20160326.001.h5')\n",
    "\n",
    "# def list_datasets(file_path):\n",
    "#     \"\"\"\n",
    "#     List all dataset paths in an HDF5 file.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     file_path : str\n",
    "#         Path to the HDF5 file\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     list\n",
    "#         List of dataset paths\n",
    "#     \"\"\"\n",
    "#     dataset_paths = []\n",
    "    \n",
    "#     def collect_datasets(name, obj):\n",
    "#         if isinstance(obj, h5py.Dataset):\n",
    "#             dataset_paths.append(name)\n",
    "    \n",
    "#     with h5py.File(file_path, 'r') as f:\n",
    "#         f.visititems(collect_datasets)\n",
    "    \n",
    "#     return dataset_paths\n",
    "\n",
    "# # Example usage:\n",
    "# # paths = list_datasets('your_file.h5')\n",
    "# # print(\"\\nDataset paths:\", *paths, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>recno</th>\n",
       "      <th>kindat</th>\n",
       "      <th>kinst</th>\n",
       "      <th>ut1_unix</th>\n",
       "      <th>...</th>\n",
       "      <th>gdlonr</th>\n",
       "      <th>los_tec</th>\n",
       "      <th>dlos_tec</th>\n",
       "      <th>tec</th>\n",
       "      <th>azm</th>\n",
       "      <th>elm</th>\n",
       "      <th>gdlat</th>\n",
       "      <th>glon</th>\n",
       "      <th>rec_bias</th>\n",
       "      <th>drec_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458950e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>23.154556</td>\n",
       "      <td>0.374467</td>\n",
       "      <td>12.409058</td>\n",
       "      <td>134.274796</td>\n",
       "      <td>27.289396</td>\n",
       "      <td>35.299515</td>\n",
       "      <td>145.801300</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458950e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>16.347767</td>\n",
       "      <td>0.373366</td>\n",
       "      <td>11.964964</td>\n",
       "      <td>57.927349</td>\n",
       "      <td>44.170170</td>\n",
       "      <td>40.664635</td>\n",
       "      <td>144.457001</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458950e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>4.626015</td>\n",
       "      <td>0.202011</td>\n",
       "      <td>4.393531</td>\n",
       "      <td>-11.427274</td>\n",
       "      <td>70.761436</td>\n",
       "      <td>40.141891</td>\n",
       "      <td>140.865005</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458950e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>18.365589</td>\n",
       "      <td>2.093730</td>\n",
       "      <td>11.724884</td>\n",
       "      <td>-50.269512</td>\n",
       "      <td>35.884354</td>\n",
       "      <td>41.573429</td>\n",
       "      <td>137.101181</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458950e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>13.004891</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>12.683059</td>\n",
       "      <td>160.805191</td>\n",
       "      <td>76.542198</td>\n",
       "      <td>38.450500</td>\n",
       "      <td>141.431488</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>249</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458958e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>16.955704</td>\n",
       "      <td>0.202011</td>\n",
       "      <td>12.299959</td>\n",
       "      <td>102.312950</td>\n",
       "      <td>43.569721</td>\n",
       "      <td>38.411732</td>\n",
       "      <td>144.929672</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>249</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458958e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>21.247169</td>\n",
       "      <td>2.093730</td>\n",
       "      <td>18.908945</td>\n",
       "      <td>-127.848763</td>\n",
       "      <td>61.310795</td>\n",
       "      <td>38.115734</td>\n",
       "      <td>139.506317</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>249</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458958e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>53.092110</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>22.182133</td>\n",
       "      <td>165.859543</td>\n",
       "      <td>16.990219</td>\n",
       "      <td>31.303854</td>\n",
       "      <td>143.416473</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>249</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458958e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>17.443150</td>\n",
       "      <td>0.488239</td>\n",
       "      <td>15.599589</td>\n",
       "      <td>37.868587</td>\n",
       "      <td>61.900990</td>\n",
       "      <td>40.368431</td>\n",
       "      <td>142.403595</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>249</td>\n",
       "      <td>3505</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.458958e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>141.132828</td>\n",
       "      <td>37.239082</td>\n",
       "      <td>0.187081</td>\n",
       "      <td>22.663685</td>\n",
       "      <td>-177.384491</td>\n",
       "      <td>33.359192</td>\n",
       "      <td>34.801807</td>\n",
       "      <td>140.893463</td>\n",
       "      <td>-13.615938</td>\n",
       "      <td>1.300858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1758 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  month  day  hour  min  sec  recno  kindat  kinst      ut1_unix  \\\n",
       "0     2016      3   26     0    0    0      0    3505   8000  1.458950e+09   \n",
       "1     2016      3   26     0    0    0      0    3505   8000  1.458950e+09   \n",
       "2     2016      3   26     0    0    0      0    3505   8000  1.458950e+09   \n",
       "3     2016      3   26     0    0    0      0    3505   8000  1.458950e+09   \n",
       "4     2016      3   26     0    0    0      0    3505   8000  1.458950e+09   \n",
       "...    ...    ...  ...   ...  ...  ...    ...     ...    ...           ...   \n",
       "1753  2016      3   26     2    4   30    249    3505   8000  1.458958e+09   \n",
       "1754  2016      3   26     2    4   30    249    3505   8000  1.458958e+09   \n",
       "1755  2016      3   26     2    4   30    249    3505   8000  1.458958e+09   \n",
       "1756  2016      3   26     2    4   30    249    3505   8000  1.458958e+09   \n",
       "1757  2016      3   26     2    4   30    249    3505   8000  1.458958e+09   \n",
       "\n",
       "      ...      gdlonr    los_tec  dlos_tec        tec         azm        elm  \\\n",
       "0     ...  141.132828  23.154556  0.374467  12.409058  134.274796  27.289396   \n",
       "1     ...  141.132828  16.347767  0.373366  11.964964   57.927349  44.170170   \n",
       "2     ...  141.132828   4.626015  0.202011   4.393531  -11.427274  70.761436   \n",
       "3     ...  141.132828  18.365589  2.093730  11.724884  -50.269512  35.884354   \n",
       "4     ...  141.132828  13.004891  0.908312  12.683059  160.805191  76.542198   \n",
       "...   ...         ...        ...       ...        ...         ...        ...   \n",
       "1753  ...  141.132828  16.955704  0.202011  12.299959  102.312950  43.569721   \n",
       "1754  ...  141.132828  21.247169  2.093730  18.908945 -127.848763  61.310795   \n",
       "1755  ...  141.132828  53.092110  0.908312  22.182133  165.859543  16.990219   \n",
       "1756  ...  141.132828  17.443150  0.488239  15.599589   37.868587  61.900990   \n",
       "1757  ...  141.132828  37.239082  0.187081  22.663685 -177.384491  33.359192   \n",
       "\n",
       "          gdlat        glon   rec_bias  drec_bias  \n",
       "0     35.299515  145.801300 -13.615938   1.300858  \n",
       "1     40.664635  144.457001 -13.615938   1.300858  \n",
       "2     40.141891  140.865005 -13.615938   1.300858  \n",
       "3     41.573429  137.101181 -13.615938   1.300858  \n",
       "4     38.450500  141.431488 -13.615938   1.300858  \n",
       "...         ...         ...        ...        ...  \n",
       "1753  38.411732  144.929672 -13.615938   1.300858  \n",
       "1754  38.115734  139.506317 -13.615938   1.300858  \n",
       "1755  31.303854  143.416473 -13.615938   1.300858  \n",
       "1756  40.368431  142.403595 -13.615938   1.300858  \n",
       "1757  34.801807  140.893463 -13.615938   1.300858  \n",
       "\n",
       "[1758 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "def extract_h5_measurements(file_path, dataset_path, n_measurements=500):\n",
    "    \"\"\"\n",
    "    Extract the first n measurements from an HDF5 file into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the HDF5 file\n",
    "    dataset_path : str\n",
    "        Path to the dataset within the HDF5 file\n",
    "    n_measurements : int, optional\n",
    "        Number of measurements to extract (default: 500)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the extracted measurements\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # Get the dataset\n",
    "            dataset = f[dataset_path]\n",
    "            \n",
    "            # Extract first n_measurements\n",
    "            data = dataset[:n_measurements]\n",
    "            # Filter for stations with certain gdlon and gdlat\n",
    "            filtered_data = data[(data['gdlonr'] >= 140) & (data['gdlonr'] <= 142) & \n",
    "                                 (data['gdlatr'] >= 39) & (data['gdlatr'] <= 41)]\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(filtered_data)\n",
    "            \n",
    "            return df\n",
    "            \n",
    "    except KeyError:\n",
    "        print(f\"Dataset {dataset_path} not found in file\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        \n",
    "# Example usage:\n",
    "df = extract_h5_measurements('/mnt/c/Users/fadri_oudurqw/Downloads/los_20160326.001.h5', 'Data/Table Layout', n_measurements=100_000_00)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
